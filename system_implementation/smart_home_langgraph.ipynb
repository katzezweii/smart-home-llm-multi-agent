{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.171703Z",
     "start_time": "2026-01-05T04:14:45.696435Z"
    }
   },
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -r requirements.txt"
   ],
   "outputs": [],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.176848Z",
     "start_time": "2026-01-05T04:14:46.175132Z"
    }
   },
   "cell_type": "code",
   "source": "# %pip show langchain langchain-core langchain-community langgraph langchain-ollama",
   "id": "d03a90e074e08d55",
   "outputs": [],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.194632Z",
     "start_time": "2026-01-05T04:14:46.182437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"gemma2\",\n",
    "     temperature= 0.0,\n",
    ")"
   ],
   "id": "50ead37703824ec7",
   "outputs": [],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.201388Z",
     "start_time": "2026-01-05T04:14:46.198658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import List, Optional, Dict, Any, TypedDict, Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class SmartHomeState(TypedDict, total=False):\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "    # Intent processing\n",
    "    complexity_score: int\n",
    "    infos: List[str]\n",
    "    original_user_input: str\n",
    "    task_queue: List[dict]\n",
    "    key_modifiers: List[str]\n",
    "\n",
    "    # Collaboration\n",
    "    collaboration_request: Dict\n",
    "    pending_task: Optional[Dict[str, Any]]\n",
    "    task_history:List[dict]\n",
    "\n",
    "    # Agent responses\n",
    "    clock_response: Optional[str]\n",
    "    clock_result: Optional[str]\n",
    "    calendar_response: Optional[str]\n",
    "    calendar_result: Optional[str]\n",
    "    search_engine_response: Optional[str]\n",
    "    search_engine_result: Optional[str]\n",
    "    tv_display_response: Optional[str]\n",
    "    tv_display_result: Optional[str]\n",
    "    fridge_response: Optional[str]\n",
    "    fridge_result: Optional[str]\n",
    "\n",
    "    lighting_response: Optional[str]\n",
    "    lighting_result: Optional[str]\n",
    "    thermostat_response: Optional[str]\n",
    "    thermostat_result: Optional[str]\n",
    "    audio_system_response: Optional[str]\n",
    "    audio_system_result: Optional[str]\n"
   ],
   "id": "90d6bab6563aeee5",
   "outputs": [],
   "execution_count": 76
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**HUMAN NODE**",
   "id": "846f0b9d27aa48fd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.207494Z",
     "start_time": "2026-01-05T04:14:46.205232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.types import Command,interrupt\n",
    "\n",
    "def human(state: SmartHomeState) -> Command:\n",
    "\n",
    "    user_input = interrupt(value=\"wait for user input...\")\n",
    "    if user_input.strip().lower() in {\"q\", \"quit\", \"exit\"}:\n",
    "        raise SystemExit\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": state[\"messages\"] + [\n",
    "                {\"role\": \"human\", \"content\": user_input}\n",
    "            ]\n",
    "        },\n",
    "        goto= \"intent_analysis\"\n",
    "    )"
   ],
   "id": "fffdd0efbf36b233",
   "outputs": [],
   "execution_count": 77
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**INTENT Analysis**",
   "id": "cfae1a8676114fe9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.214672Z",
     "start_time": "2026-01-05T04:14:46.212017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "def intent_analysis(state: SmartHomeState) -> Command:\n",
    "\n",
    "    user_message= get_user_input(state)\n",
    "\n",
    "    if not user_message:\n",
    "        raise ValueError(\"No user message found for intent classification\")\n",
    "\n",
    "    parser = JsonOutputParser()\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"Analyze the user's smart home request.\n",
    "\n",
    "        User input: {user_message}\n",
    "\n",
    "        Task 1: Split into separate information units\n",
    "        - One info = one intent, feeling, or fact\n",
    "        - Keep all details: what, how, when, why, where\n",
    "        - If \"and\" connects independent intents or requests, split them (e.g., 'I'm hungry and tired' = two separate feelings)\"\n",
    "\n",
    "        Task 2: Extract key modifiers\n",
    "        Find words that specify HOW, WHEN, WHERE, HOW MUCH. These are easy to miss:\n",
    "\n",
    "        Time-related:\n",
    "        - \"gradually\", \"slowly\", \"immediately\"\n",
    "        - \"at 10pm\", \"for 30 minutes\", \"until tonight\"\n",
    "        - \"today\", \"tomorrow\", \"this afternoon\"\n",
    "\n",
    "        Location:\n",
    "        - \"in the bedroom\", \"in the living room\"\n",
    "\n",
    "        Manner/degree:\n",
    "        - \"very\", \"extremely\", \"slightly\"\n",
    "        - \"quietly\", \"brightly\", \"warmly\"\n",
    "        - \"dim\", \"bright\", \"loud\"\n",
    "\n",
    "        Quantity/negation:\n",
    "        - \"all\", \"some\", \"half\"\n",
    "        - \"no music\", \"don't\", \"without\"\n",
    "\n",
    "        Examples:\n",
    "\n",
    "        Input: \"I want the lights to dim gradually starting at 10pm\"\n",
    "        {{\n",
    "        \"infos\": [\"I want the lights to dim gradually starting at 10pm\"],\n",
    "        \"key_modifiers\": [\"gradually\", \"starting at 10pm\", \"dim\"]\n",
    "        }}\n",
    "\n",
    "        Input: \"Play some quiet music in the bedroom for 30 minutes\"\n",
    "        {{\n",
    "        \"infos\": [\"Play some quiet music in the bedroom for 30 minutes\"],\n",
    "        \"key_modifiers\": [\"quiet\", \"in the bedroom\", \"for 30 minutes\"]\n",
    "        }}\n",
    "\n",
    "        Input: \"I'm tired and need to relax\"\n",
    "        {{\n",
    "        \"infos\": [\"I'm tired\", \"need to relax\"],\n",
    "        \"key_modifiers\": []\n",
    "        }}\n",
    "\n",
    "        Input: \"Turn on very bright lights, no music please\"\n",
    "        {{\n",
    "        \"infos\": [\"Turn on very bright lights\", \"no music please\"],\n",
    "        \"key_modifiers\": [\"very bright\", \"no music\"]\n",
    "        }}\n",
    "\n",
    "        {format_instructions}\n",
    "\n",
    "        Output ONLY valid JSON, no markdown code blocks, no explanations, no extra comma\n",
    "\n",
    "        Output format:\n",
    "        {{\n",
    "        \"infos\": [\"info1\", \"info2\"],\n",
    "        \"key_modifiers\": [\"modifier1\", \"modifier2\"]\n",
    "        }}\n",
    "        \"\"\",\n",
    "        input_variables=[\"user_message\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    result = chain.invoke({\n",
    "        \"user_message\": user_message,\n",
    "    })\n",
    "\n",
    "    infos = result.get(\"infos\")\n",
    "    complexity_score = len(infos)\n",
    "    key_modifiers = result.get(\"key_modifiers\",[])\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"complexity_score\": complexity_score,\n",
    "            \"infos\": infos,\n",
    "            \"key_modifiers\": key_modifiers,\n",
    "            \"original_user_input\": user_message,\n",
    "        },\n",
    "        goto=\"task_planner\"\n",
    "    )"
   ],
   "id": "fd80486f94d78ff0",
   "outputs": [],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.223030Z",
     "start_time": "2026-01-05T04:14:46.221339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def get_user_input(state: SmartHomeState) -> str:\n",
    "    \"\"\"\n",
    "    Get user input from state\n",
    "    \"\"\"\n",
    "    for msg in state[\"messages\"]:\n",
    "        if isinstance(msg, HumanMessage):\n",
    "            return msg.content\n",
    "        elif isinstance(msg, dict) and msg.get(\"role\") == \"human\":\n",
    "            return msg.get(\"content\")\n",
    "\n",
    "    raise ValueError(\"No user input found\")"
   ],
   "id": "593de1c66afb87f5",
   "outputs": [],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Central Task Planner**",
   "id": "b2d9d6a856cc2694"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.231856Z",
     "start_time": "2026-01-05T04:14:46.227330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def task_planner(state: SmartHomeState) -> Command:\n",
    "\n",
    "    original_input = state.get('original_user_input')\n",
    "    task_queue = state.get('task_queue', [])\n",
    "\n",
    "    # Continue executing the remaining tasks\n",
    "    if task_queue:\n",
    "        current_task = task_queue[0]\n",
    "        return Command(\n",
    "            update={},\n",
    "            goto=f\"{current_task['device']}_agent\"\n",
    "        )\n",
    "\n",
    "    # Fresh start, original_input is not empty\n",
    "    if original_input:\n",
    "\n",
    "        infos = state.get('infos', [])\n",
    "        key_modifiers = state.get('key_modifiers', [])\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are the task planner for a smart home system.\n",
    "\n",
    "            User input: {original_input}\n",
    "\n",
    "            Reference: Infos = {infos}, Key modifiers = {key_modifiers} (Use as reference, but trust original user input if conflict)\n",
    "\n",
    "            Your responsibility is to identify the user's main goal and assign it to the most appropriate device as a high-level task.\n",
    "\n",
    "            Rule for task planner:\n",
    "            1. Assign each goal to ONE primary device\n",
    "            2. Describe WHAT needs to be done, PRESERVING ALL KEY DETAILS from user's request\n",
    "            - Time references: \"today\", \"tonight\", \"next Monday\", \"this weekend\", \"tomorrow\"\n",
    "            - Quantities: \"for 6 people\", \"quick\", \"large\"\n",
    "            - Constraints: \"vegan\", \"easy\", \"outdoor\", \"under 30 minutes\"\n",
    "            - Locations: \"near me\", \"in the bedroom\"\n",
    "            3. DO NOT predict or specify collaboration between devices\n",
    "            4. Trust individual agents to determine if they need help from other devices\n",
    "\n",
    "            Available devices and their capabilities:\n",
    "            - lighting: adjust lights, create atmosphere through lighting\n",
    "            - thermostat: temperature control, create atmosphere through temperature\n",
    "            - audio_system: play music, adjust volume, create atmosphere through audio_system\n",
    "            - clock: provide current time, set alarms and timers, start or stop stopwatch\n",
    "            - calendar: add schedule/reminders, provide information about schedule\n",
    "            - fridge: provide food inventory (doesn't know any recipes)\n",
    "            - search_engine: general information, recipes information, weather\n",
    "            - tv_display: show/display visual content\n",
    "\n",
    "            EXAMPLES:\n",
    "\n",
    "            # === CALENDAR & SCHEDULE SCENARIOS ===\n",
    "            Input: \"What's on my calendar today?\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"calendar\", \"action\": \"What's on my calendar today?\"}}\n",
    "            ]}}\n",
    "\n",
    "            Input: \"Where is the location for my next appointment?\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"calendar\", \"action\": \"check the location of my next appointment\"}}\n",
    "            ]}}\n",
    "\n",
    "            Input: \"What time is my next appointment?\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"calendar\", \"action\": \"check the start time of my next appointment\"}}\n",
    "            ]}}\n",
    "\n",
    "            # === TIME & ALARM SCENARIOS ===\n",
    "\n",
    "            # Set Alarm\n",
    "            Input: \"I need to wake up at tomorrow 7am\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"clock\", \"action\": \"set alarm at 7am for wake up\"}}\n",
    "            ]}}\n",
    "\n",
    "            # === MUSIC SCENARIOS ===\n",
    "\n",
    "            \"play relaxing music\"\n",
    "            Note: User only mentioned music\n",
    "            {{\"task_queue\": [{{\"device\": \"audio_system\", \"action\": \"play relaxing music\"}}]}}\n",
    "\n",
    "            # === FOOD & COOKING SCENARIOS ===\n",
    "\n",
    "            # Hungry\n",
    "            Input: \"Do we have any milk? Is it about to expire?\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"fridge\", \"action\": \"Is there any milk in the fridge? If there is milk, is it about to expire?\"}}\n",
    "            ]}}\n",
    "\n",
    "            Input: \"What dishes can I make based on the ingredients I have in the fridge?\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"fridge\", \"action\": \"what's in the fridge\"}},\n",
    "                {{\"device\": \"search_engine\", \"action\": \"suggest recipes using ingredients you already have\"}}\n",
    "            ]}}\n",
    "\n",
    "            # === INFORMATION SEARCH SCENARIOS ===\n",
    "\n",
    "            Input: \"recommend some songs\"\n",
    "            {{\"task_queue\": [{{\"device\": \"search_engine\", \"action\": \"recommend songs\"}}]}}\n",
    "\n",
    "            Input: \"what music should I listen to?\"\n",
    "            {{\"task_queue\": [{{\"device\": \"search_engine\", \"action\": \"suggest music recommendations\"}}]}}\n",
    "\n",
    "            # General Recipe Search\n",
    "            Input: \"Find me pasta recipe\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"search_engine\", \"action\": \"find a pasta recipe\"}}\n",
    "            ]}}\n",
    "\n",
    "            # General Information Search\n",
    "            Input: \"At what time does the New Year typically begin?\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"search_engine\", \"action\": \"At what time does the New Year typically begin?\"}}\n",
    "            ]}}\n",
    "\n",
    "            Input: \"I want to make 'Fried Rice'\"\n",
    "            NOTE: When a user mentions a specific dish name, it should be assigned to the search engine rather than the fridge, as the fridge does not know the recipe for that particular dish.\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"search_engine\", \"action\": \"find a 'Fried Rice' recipe\"}}\n",
    "            ]}}\n",
    "\n",
    "             # Hungry\n",
    "            Input: \"I'm hungry\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"search_engine\", \"action\": \"user is hungry, suggest quick meal options with available food\"}}\n",
    "            ]}}\n",
    "\n",
    "            # Meal Planning\n",
    "            Input: \"What should I cook tonight?\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"search_engine\", \"action\": \"suggest dinner recipes using available ingredients\"}}\n",
    "            ]}}\n",
    "\n",
    "            # === DISPLAY SCENARIOS ===\n",
    "\n",
    "            Input: \"I want to watch TV shows\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"tv_display\", \"action\": \"display TV shows content\"}}\n",
    "            ]}}\n",
    "\n",
    "            Input: \"display something on the screen\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"tv_display\", \"action\": \"display something on the screen\"}}\n",
    "            ]}}\n",
    "\n",
    "            # === MULTI-ASPECT SCENARIOS ===\n",
    "\n",
    "            Input: \"play relaxing music for 30 minutes\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"audio_system\", \"action\": \"play relaxing music\"}},\n",
    "                {{\"device\": \"clock\", \"action\": \"set timer for 30 minutes to stop music\"}}\n",
    "            ]}}\n",
    "\n",
    "            Input: \"play music for 1 hour\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"audio_system\", \"action\": \"play music\"}},\n",
    "                {{\"device\": \"clock\", \"action\": \"set timer for 1 hour to stop music\"}}\n",
    "            ]}}\n",
    "\n",
    "            Input: \"show me a movie until 10pm\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"tv_display\", \"action\": \"show me a movie\"}},\n",
    "                {{\"device\": \"clock\", \"action\": \"set reminder at 10pm to stop watching\"}}\n",
    "            ]}}\n",
    "\n",
    "            # Schedule + Environment Setup\n",
    "\n",
    "            Input: \"Show me my schedule and prepare the room for meetings\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"calendar\", \"action\": \"display today's schedule\"}},\n",
    "                {{\"device\": \"lighting\", \"action\": \"set bright lighting for meetings\"}},\n",
    "                {{\"device\": \"thermostat\", \"action\": \"set comfortable temperature for meetings\"}}\n",
    "            ]}}\n",
    "\n",
    "            # Context Preservation - Event Type\n",
    "            Input: \"I'm hosting a baby shower this afternoon. Get everything ready.\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"lighting\", \"action\": \"create welcoming atmosphere for baby shower with soft cheerful lighting\"}},\n",
    "                {{\"device\": \"thermostat\", \"action\": \"create comfortable temperature for baby shower guests\"}},\n",
    "                {{\"device\": \"audio_system\", \"action\": \"create pleasant atmosphere for baby shower with gentle background music\"}}\n",
    "            ]}}\n",
    "\n",
    "            # Context Preservation - Activity Purpose\n",
    "            Input: \"I'm preparing for an important job interview via video call soon. Help me get ready.\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"lighting\", \"action\": \"create professional atmosphere for video interview with optimal lighting\"}},\n",
    "                {{\"device\": \"thermostat\", \"action\": \"create comfortable temperature for job interview preparation\"}},\n",
    "                {{\"device\": \"clock\", \"action\": \"set an alarm 1 hour before job interview for preparation time\"}}\n",
    "            ]}}\n",
    "\n",
    "            # === CREATE ATMOSPHERE SCENARIOS ===\n",
    "            # Comfortable scenario\n",
    "            Input:\"I'm tired and need relax\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"audio_system\", \"action\": \"play relaxing music\"}},\n",
    "                {{\"device\": \"lighting\", \"action\": \"dim the lighting to help users relax\"}},\n",
    "                {{\"device\": \"thermostat\", \"action\": \"set a comfortable temperature for users to relax better\"}}\n",
    "            ]}}\n",
    "\n",
    "            # Work Environment\n",
    "            Input: \"Make the room comfortable for working\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"lighting\", \"action\": \"create bright lighting for a comfortable work environment\"}},\n",
    "                {{\"device\": \"thermostat\", \"action\": \"set comfortable temperature for work\"}},\n",
    "                {{\"device\": \"audio_system\", \"action\": \"play calming sounds for work\"}}\n",
    "            ]}}\n",
    "\n",
    "            # Sleep Environment\n",
    "            Input: \"I'm going to bed soon\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"lighting\", \"action\": \"prepare turn off the light for sleep\"}},\n",
    "                {{\"device\": \"thermostat\", \"action\": \"set comfortable temperature for sleep\"}},\n",
    "                {{\"device\": \"audio_system\", \"action\": \"play calming sounds for sleep\"}}\n",
    "            ]}}\n",
    "\n",
    "            # Semantic Atmosphere Recognition - User describes feeling/state\n",
    "            Input: \"I just woke up and feel groggy. Help me get energized for the day ahead.\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"lighting\", \"action\": \"create energizing morning atmosphere with bright lighting to help wake up\"}},\n",
    "                {{\"device\": \"thermostat\", \"action\": \"create comfortable temperature for active morning\"}},\n",
    "                {{\"device\": \"audio_system\", \"action\": \"create motivating atmosphere with upbeat morning music\"}}\n",
    "            ]}}\n",
    "\n",
    "            # Semantic Atmosphere Recognition - User describes desired outcome\n",
    "            Input: \"I want to create the perfect reading nook atmosphere in the living room.\"\n",
    "            {{\"task_queue\": [\n",
    "                {{\"device\": \"lighting\", \"action\": \"create cozy reading atmosphere with warm focused lighting in living room\"}},\n",
    "                {{\"device\": \"thermostat\", \"action\": \"create comfortable temperature for extended reading\"}},\n",
    "                {{\"device\": \"audio_system\", \"action\": \"create calm reading atmosphere with soft instrumental background music\"}}\n",
    "            ]}}\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Format rules:\n",
    "            1. Every task MUST have both \"device\" and \"action\" fields\n",
    "            2. Output ONLY valid JSON, no markdown code blocks, no explanations\n",
    "            3. Format: {{\"task_queue\": [{{\"device\": \"device_name\", \"action\": \"complete description with context\"}}]}}\n",
    "            4. Include relevant details from user input in the action description\n",
    "\n",
    "            Output format: {{\"task_queue\": [{{\"device\": \"device_name\", \"action\": \"what to do with full context\"}}]}}\n",
    "\n",
    "            \"\"\",\n",
    "\n",
    "            input_variables=[\"original_input\", \"infos\", \"key_modifiers\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"original_input\": original_input,\n",
    "            \"infos\": infos,\n",
    "            \"key_modifiers\": key_modifiers,\n",
    "        })\n",
    "        new_task_queue = result.get(\"task_queue\")\n",
    "\n",
    "        #print(f\"DEBUG: LLM result = {result}\")\n",
    "        current_task = new_task_queue[0]\n",
    "        return Command(\n",
    "            update={\n",
    "                \"task_queue\": new_task_queue,\n",
    "                \"original_user_input\": \"\"\n",
    "            },\n",
    "            goto=f\"{current_task['device']}_agent\"\n",
    "        )\n",
    "\n",
    "    #print(\"DEBUG: All tasks completed\")\n",
    "    return Command(update={})"
   ],
   "id": "3491c547f498243b",
   "outputs": [],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Clock Agent**",
   "id": "f4757b9dc199d0d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.243423Z",
     "start_time": "2026-01-05T04:14:46.237514Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clock_agent(state: SmartHomeState) -> Command:\n",
    "    task_queue = state.get(\"task_queue\", [])\n",
    "    collaboration_request = state.get(\"collaboration_request\")\n",
    "    pending_task = state.get(\"pending_task\")\n",
    "    task_history = state.get(\"task_history\",[])\n",
    "\n",
    "    # Branch 1: Respond to collaboration requests from other agents\n",
    "    if collaboration_request and collaboration_request.get(\"target\") == \"clock\":\n",
    "        requester = collaboration_request.get(\"requester\")\n",
    "        request = collaboration_request.get(\"request\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Clock Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Provide current time\n",
    "            2. Set or cancel alarms with default alarm sound\n",
    "            3. Set or cancel timers\n",
    "            4. Start or stop a stopwatch\n",
    "\n",
    "            You received a collaboration request from {requester} agent.\n",
    "            Request: {request}\n",
    "\n",
    "            Provide the requested information directly. Simulate reasonable time data.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"your response\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"requester\", \"request\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"requester\": requester,\n",
    "            \"request\": request,\n",
    "        })\n",
    "        clock_response = result.get(\"response\")\n",
    "\n",
    "        new_entry = {\n",
    "            \"device\": \"clock\",\n",
    "            \"type\": \"collaboration_response\",\n",
    "            \"action_taken\": request,\n",
    "            \"result\": clock_response,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"clock_response\": clock_response,\n",
    "                \"collaboration_request\": {},\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=f\"{requester}_agent\"\n",
    "        )\n",
    "\n",
    "    # Branch 2: Handling Collaborative Responses\n",
    "    elif pending_task and pending_task.get(\"device\") == \"clock\":\n",
    "        collaborator = pending_task.get(\"waiting_for\")\n",
    "        response_key = f\"{collaborator}_response\"\n",
    "        collaborator_response = state.get(response_key)\n",
    "        original_action = pending_task.get(\"action\")\n",
    "\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Clock Agent completing a task with collaboration information.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Provide current time\n",
    "            2. Set or cancel alarms with default alarm sound\n",
    "            3. Set or cancel timers\n",
    "            4.Start or stop a stopwatch\n",
    "\n",
    "            Original task: {original_action}\n",
    "            Task history (what happened before this):{task_history}\n",
    "            Collaboration request：{collaboration_request}\n",
    "            Response from {collaborator}: {collaborator_response}\n",
    "\n",
    "            Now complete the task using these information without asking user. Simulate reasonable time data.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"task completion message\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"original_action\",\"task_history\",\"collaboration_request\", \"collaborator\", \"collaborator_response\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"original_action\": original_action,\n",
    "            \"task_history\": task_history,\n",
    "            \"collaboration_request\": collaboration_request,\n",
    "            \"collaborator\": collaborator,\n",
    "            \"collaborator_response\": collaborator_response\n",
    "        })\n",
    "\n",
    "        clock_result = result.get(\"response\")\n",
    "        remaining_tasks = task_queue[1:]\n",
    "        new_entry = {\n",
    "            \"device\": \"clock\",\n",
    "            \"type\": \"task_completion\",\n",
    "            \"action_taken\": original_action,\n",
    "            \"result\": clock_result,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"clock_result\": clock_result,\n",
    "                \"task_queue\": remaining_tasks,\n",
    "                \"pending_task\": None,\n",
    "                \"collaboration_request\": {},\n",
    "                f\"{collaborator}_response\": None,  # 清空临时协作响应\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=\"task_planner\"\n",
    "        )\n",
    "\n",
    "    # Branch 3: Handling New Tasks\n",
    "    elif task_queue and task_queue[0].get(\"device\") == \"clock\":\n",
    "        action = task_queue[0].get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Clock Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Provide current time\n",
    "            2. Set or cancel alarms with default alarm sound\n",
    "            3. Set or cancel timers\n",
    "            4. Start or stop a stopwatch\n",
    "\n",
    "            Current task: {action}\n",
    "            Task history: {task_history} which you will know what other device already done\n",
    "\n",
    "            Important: Check task_history first before requesting collaboration\n",
    "            1. Review the task_history carefully\n",
    "            2. Check if another agent has already provided the information you need\n",
    "            3. Only request collaboration if the required information is genuinely NOT in task_history\n",
    "\n",
    "            Decide: Can you complete this independently with your capabilities and task history?\n",
    "            If YES: Complete the task directly without asking the user\n",
    "            If NO: Identify what you need and request help from appropriate agent\n",
    "\n",
    "            Don't ask the user for clarification. Make reasonable assumptions when needed.\n",
    "\n",
    "            Other agents available for collaboration:\n",
    "            calendar (provide information(time,location,with who) about schedule/events), audio_system (music), lighting (adjust lights and create lighting scenes),tv_display(show information),thermostat(temperature control),search_engine(provide external information),fridge(food inventory)\n",
    "\n",
    "            Examples:\n",
    "\n",
    "            action: \"set alarm for tomorrow 7am\"\n",
    "            {{\"response\": \"Alarm set for 7:00 AM on Saturday, September 27, 2025\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"remind me 10 minutes before my next meeting\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"calendar\", \"request\": \"It is now 2 PM. What time is my next scheduled meeting today?\"}}}}\n",
    "\n",
    "            action: \"remind me next event after 30 minutes\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"calendar\", \"request\": \"It is now 1 PM. What time is my next scheduled meeting today?\"}}}}\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output ONLY pure JSON.\n",
    "            Output format: {{\"response\": \"your result\" or \"\", \"collaboration_request\": {{\"target\": \"agent_name\", \"request\": \"what you need\"}} or {{}}}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"action\",\"task_history\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"action\": action,\n",
    "            \"task_history\": task_history,\n",
    "        })\n",
    "\n",
    "        if result.get(\"collaboration_request\") and result[\"collaboration_request\"].get(\"target\"):\n",
    "            collaboration = result[\"collaboration_request\"]\n",
    "\n",
    "            new_entry = {\n",
    "                \"device\": \"clock\",\n",
    "                \"type\": \"collaboration_request\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": {\n",
    "                    \"target\": collaboration[\"target\"],\n",
    "                    \"request\": collaboration[\"request\"],\n",
    "                },\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"collaboration_request\": {\n",
    "                        \"requester\": \"clock\",\n",
    "                        \"target\": collaboration[\"target\"],\n",
    "                        \"request\": collaboration[\"request\"],\n",
    "                    },\n",
    "                    \"pending_task\": {\n",
    "                        \"device\": \"clock\",\n",
    "                        \"action\": action,\n",
    "                        \"waiting_for\": collaboration[\"target\"]\n",
    "                    },\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=f\"{collaboration['target']}_agent\"\n",
    "            )\n",
    "        else:\n",
    "            remaining_tasks = task_queue[1:]\n",
    "            clock_result = result.get(\"response\")\n",
    "            new_entry = {\n",
    "                \"device\": \"clock\",\n",
    "                \"type\": \"task_completion\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": clock_result,\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"clock_result\": clock_result,\n",
    "                    \"task_queue\": remaining_tasks,\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=\"task_planner\"\n",
    "            )"
   ],
   "id": "57d55b551a2e890a",
   "outputs": [],
   "execution_count": 81
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Search Engine**",
   "id": "8f59511503297576"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.251466Z",
     "start_time": "2026-01-05T04:14:46.245379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search_engine_agent(state: SmartHomeState) -> Command:\n",
    "    task_queue = state.get(\"task_queue\", [])\n",
    "    collaboration_request = state.get(\"collaboration_request\")\n",
    "    pending_task = state.get(\"pending_task\")\n",
    "    task_history = state.get(\"task_history\",[])\n",
    "\n",
    "    # branch 1\n",
    "    if collaboration_request and collaboration_request.get(\"target\") == \"search_engine\":\n",
    "        requester = collaboration_request.get(\"requester\")\n",
    "        request = collaboration_request.get(\"request\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Search Engine Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Provide weather information (any time: past, present, future)\n",
    "            2. Provide recipes and cooking information\n",
    "            3. Provide general information and knowledge\n",
    "            4. Provide home management tips and advice\n",
    "\n",
    "            You received a collaboration request from {requester} agent.\n",
    "            Request: {request}\n",
    "\n",
    "            Provide the information they need directly. Simulate a reasonable search result.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            Response format: Plain text, items separated by commas, no quotation marks or special formatting.\n",
    "\n",
    "            Examples:\n",
    "            Request: \"find restaurants\"\n",
    "            {{\"response\": \"Restaurants nearby: Luigi's Pizza at Main Street 10, Sushi House at Park Ave 25, Burger Palace at Market Square 5\"}}\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output format: {{\"response\": \"your simulated search result\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"requester\", \"request\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"requester\": requester,\n",
    "            \"request\": request\n",
    "        })\n",
    "        search_engine_response = result.get(\"response\")\n",
    "        new_entry = {\n",
    "            \"device\": \"search_engine\",\n",
    "            \"type\": \"collaboration_response\",\n",
    "            \"action_taken\": request,\n",
    "            \"result\": search_engine_response,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"search_engine_response\": search_engine_response,\n",
    "                \"collaboration_request\": {},\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=f\"{requester}_agent\"\n",
    "        )\n",
    "\n",
    "    # branch 2\n",
    "    elif pending_task and pending_task.get(\"device\") == \"search_engine\":\n",
    "        collaborator = pending_task.get(\"waiting_for\")\n",
    "        response_key = f\"{collaborator}_response\"\n",
    "        collaborator_response = state.get(response_key)\n",
    "        original_action = pending_task.get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Search Engine Agent completing a task with collaboration information.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Provide weather information (any time: past, present, future)\n",
    "            2. Provide recipes and cooking information\n",
    "            3. Provide general information and knowledge\n",
    "            4. Provide home management tips and advice\n",
    "\n",
    "            Original task: {original_action}\n",
    "            Task history (what happened before this): {task_history}\n",
    "            The content of your collaboration request：{collaboration_request}\n",
    "            Information received from {collaborator}: {collaborator_response}\n",
    "\n",
    "            Response format: Plain text, items separated by commas, no quotation marks or special formatting.\n",
    "\n",
    "            Now complete the task using these information without asking user.\n",
    "            Provide a simulated search result.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"search result\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"original_action\",\"task_history\",\"collaboration_request\", \"collaborator\", \"collaborator_response\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"original_action\": original_action,\n",
    "            \"task_history\": task_history,\n",
    "            \"collaboration_request\": collaboration_request,\n",
    "            \"collaborator\": collaborator,\n",
    "            \"collaborator_response\": collaborator_response\n",
    "        })\n",
    "        search_engine_result = result.get(\"response\")\n",
    "        remaining_tasks = task_queue[1:]\n",
    "        new_entry = {\n",
    "            \"device\": \"search_engine\",\n",
    "            \"type\": \"task_completion\",\n",
    "            \"action_taken\": original_action,\n",
    "            \"result\": search_engine_result,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"search_engine_result\": search_engine_result,\n",
    "                \"task_queue\": remaining_tasks,\n",
    "                \"pending_task\": None,\n",
    "                \"collaboration_request\": {},\n",
    "                f\"{collaborator}_response\": None,\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=\"task_planner\"\n",
    "        )\n",
    "\n",
    "    # branch 3\n",
    "    elif task_queue and task_queue[0].get(\"device\") == \"search_engine\":\n",
    "        action = task_queue[0].get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Search Engine Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Provide weather information (any time: past, present, future)\n",
    "            2. Provide recipes and cooking information\n",
    "            3. Provide general information and knowledge\n",
    "            4. Provide home management tips and advice\n",
    "\n",
    "            Current task: {action}\n",
    "            Default location: Hamburg, Germany\n",
    "            Task history: {task_history} which you will know what other device already done\n",
    "\n",
    "            Important:\n",
    "            1. Always provide simulated results - never say information is 'unavailable'\n",
    "            2. Never ask the user questions or offer to do additional searches\n",
    "            3. Make reasonable assumptions and provide complete answers directly\n",
    "            4. For general advice questions, provide answers without needing other agents\n",
    "            5. When advice involves weather, include simulated weather data directly\n",
    "\n",
    "            SPECIAL RULE FOR RECIPE SEARCHES:\n",
    "            When the task involves finding recipes 'based on available ingredients' or 'based on what's in fridge':\n",
    "            Check task_history first: Has fridge already provided ingredient information?\n",
    "            If YES: Use those ingredients to suggest recipes\n",
    "            If NO: Request collaboration to get available ingredients\n",
    "\n",
    "            Response format: Plain text, items separated by commas, no quotation marks or special formatting.\n",
    "\n",
    "            Decide: Can you complete this independently with your capabilities and task history?\n",
    "\n",
    "            If YES: Provide complete simulated results\n",
    "            If NO: Only collaborate if you need SPECIFIC data you cannot simulate\n",
    "\n",
    "            Other agents available for collaboration:\n",
    "            tv_display (show visual content on screens), calendar(check/add appointments and schedule),clock (check time, alarms, timers), fridge (food inventory), lighting (lights control), thermostat (temperature control), audio_system (music or volume control)\n",
    "\n",
    "            Examples:\n",
    "\n",
    "            action: \"find current weather in Hamburg\"\n",
    "            {{\"response\": \"Hamburg weather: 18°C, partly cloudy, light breeze. Expected high of 22°C today.\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"find simple recipes using chicken and rice\"\n",
    "            {{\"response\": \"Found 3 simple recipes: 1) Chicken Rice Bowl, 2) One-Pot Chicken and Rice, 3) Asian Chicken Fried Rice. Each takes 30-40 minutes.\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"recommend music\"\n",
    "            {{\"response\": \"Music recommendations: Blinding Lights by The Weeknd, As It Was by Harry Styles, Break My Heart by Dua Lipa, Industry Baby by Lil Nas X, Heat Waves by Glass Animals\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"recommend cozy atmosphere music\"\n",
    "            {{\"response\": \"For a cozy atmosphere, try instrumental music with mellow tempos and warm tones. Suggestions: Weightless by Marconi Union, Clair de Lune by Claude Debussy, Nuvole Bianche by Ludovico Einaudi, Watermark by Enya\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"suggest recipes based on ingredients\"\n",
    "            Note: This requires current available food information in fridge\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"fridge\", \"request\": \"list available ingredients for meal planning\"}}}}\n",
    "\n",
    "            action: \"suggest recipes using available ingredients\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"fridge\", \"request\": \"check what food items are available\"}}}}\n",
    "\n",
    "            action: \"what's the weather like at my next scheduled location?\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"calendar\", \"request\": \"check the location for the next schedule\"}}}}\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output ONLY JSON\n",
    "            Output format: {{\"response\": \"your search result\", \"collaboration_request\": {{}} }}\n",
    "            \"\"\",\n",
    "            input_variables=[\"action\",\"task_history\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"action\": action,\n",
    "            \"task_history\": task_history,\n",
    "        })\n",
    "\n",
    "        if result.get(\"collaboration_request\") and result[\"collaboration_request\"].get(\"target\"):\n",
    "            collaboration = result[\"collaboration_request\"]\n",
    "\n",
    "            new_entry = {\n",
    "                \"device\": \"search_engine\",\n",
    "                \"type\": \"collaboration_request\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": {\n",
    "                    \"target\" : collaboration[\"target\"],\n",
    "                    \"request\" : collaboration[\"request\"],\n",
    "                },\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"collaboration_request\": {\n",
    "                        \"requester\": \"search_engine\",\n",
    "                        \"target\": collaboration[\"target\"],\n",
    "                        \"request\": collaboration[\"request\"],\n",
    "                    },\n",
    "                    \"pending_task\": {\n",
    "                        \"device\": \"search_engine\",\n",
    "                        \"action\": action,\n",
    "                        \"waiting_for\": collaboration[\"target\"]\n",
    "                    },\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=f\"{collaboration['target']}_agent\"\n",
    "            )\n",
    "        else:\n",
    "            remaining_tasks = task_queue[1:]\n",
    "            search_engine_result = result.get(\"response\")\n",
    "            new_entry = {\n",
    "                \"device\": \"search_engine\",\n",
    "                \"type\": \"task_completion\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": search_engine_result,\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"search_engine_result\": search_engine_result ,\n",
    "                    \"task_queue\": remaining_tasks,\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=\"task_planner\"\n",
    "            )"
   ],
   "id": "7e94ff05f71d8359",
   "outputs": [],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Calendar**",
   "id": "2bbc953cfd44512e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.260766Z",
     "start_time": "2026-01-05T04:14:46.255250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calendar_agent(state: SmartHomeState) -> Command:\n",
    "    task_queue = state.get(\"task_queue\", [])\n",
    "    collaboration_request = state.get(\"collaboration_request\")\n",
    "    pending_task = state.get(\"pending_task\")\n",
    "    task_history = state.get(\"task_history\",[])\n",
    "\n",
    "    if collaboration_request and collaboration_request.get(\"target\") == \"calendar\":\n",
    "        requester = collaboration_request.get(\"requester\")\n",
    "        request = collaboration_request.get(\"request\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Calendar Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Add appointments/reminders/meeting\n",
    "            2. Cancel or reschedule appointments\n",
    "            3. Provide information about schedule/appointments/reminders (time, location, with who)\n",
    "\n",
    "            You received a collaboration request from {requester} agent.\n",
    "            Request: {request}\n",
    "\n",
    "            Provide schedule information directly. Simulate reasonable calendar data.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"your simulated schedule information\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"requester\", \"request\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"requester\": requester,\n",
    "            \"request\": request,\n",
    "        })\n",
    "\n",
    "        calendar_response = result.get(\"response\")\n",
    "        new_entry = {\n",
    "            \"device\": \"calendar\",\n",
    "            \"type\": \"collaboration_response\",\n",
    "            \"action_taken\": request,\n",
    "            \"result\": calendar_response,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"calendar_response\": calendar_response,\n",
    "                \"collaboration_request\": {},\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=f\"{requester}_agent\"\n",
    "        )\n",
    "\n",
    "    elif pending_task and pending_task.get(\"device\") == \"calendar\":\n",
    "\n",
    "        collaborator = pending_task.get(\"waiting_for\")\n",
    "        response_key = f\"{collaborator}_response\"\n",
    "        collaborator_response = state.get(response_key)\n",
    "        original_action = pending_task.get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Calendar Agent completing a task with collaboration information.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Add appointments/reminders/meeting\n",
    "            2. Cancel or reschedule appointments\n",
    "            3. Provide information about schedule/appointments/reminders (time, location, with who)\n",
    "\n",
    "            Original task: {original_action}\n",
    "            Task history (what happened before this task):{task_history}\n",
    "            Collaboration request：{collaboration_request}\n",
    "            Request from {collaborator}: {collaborator_response}\n",
    "\n",
    "            Now simulate the calendar operation and provide the result and make reasonable assumptions.\n",
    "            Don't ask the user questions\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"task completion message\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"original_action\",\"task_history\",\"collaboration_request\",\"collaborator\", \"collaborator_response\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"original_action\": original_action,\n",
    "            \"task_history\": task_history,\n",
    "            \"collaboration_request\": collaboration_request,\n",
    "            \"collaborator\": collaborator,\n",
    "            \"collaborator_response\": collaborator_response\n",
    "        })\n",
    "        calendar_result = result.get(\"response\")\n",
    "        remaining_tasks = task_queue[1:]\n",
    "        new_entry = {\n",
    "            \"device\": \"calendar\",\n",
    "            \"type\": \"task_completion\",\n",
    "            \"action_taken\": original_action,\n",
    "            \"result\": calendar_result,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"calendar_result\": calendar_result,\n",
    "                \"task_queue\": remaining_tasks,\n",
    "                \"pending_task\": None,\n",
    "                \"collaboration_request\": {},\n",
    "                f\"{collaborator}_response\": None,\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=\"task_planner\"\n",
    "        )\n",
    "\n",
    "    elif task_queue and task_queue[0].get(\"device\") == \"calendar\":\n",
    "        action = task_queue[0].get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Calendar Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Add appointments/reminders/meeting\n",
    "            2. Cancel or reschedule appointments\n",
    "            3. Provide information about schedule/appointments/reminders (event time, location, with who)\n",
    "\n",
    "            Current task: {action}\n",
    "            Task history : {task_history} which you will know what other device already done\n",
    "\n",
    "            Important: Check task_history first before requesting collaboration\n",
    "            1. Review what other agents have already done\n",
    "            2. Only request collaboration if needed information is not in task_history\n",
    "\n",
    "            Decide: Can you complete this independently with your capabilities and task history?\n",
    "\n",
    "            If YES: Complete the task directly without asking user\n",
    "            If NO: Identify what you need and request help from appropriate agent\n",
    "\n",
    "            Other agents available for collaboration:\n",
    "            tv_display (show/display content on screens), search_engine (look up information),clock (get current time, alarms, timers), fridge (food), lighting (lights), thermostat (temperature),audio_system (music)\n",
    "\n",
    "            Examples:\n",
    "\n",
    "            # Adding appointments\n",
    "            action: \"add a dentist appointment for next Tuesday at 3pm\"\n",
    "            {{\"response\": \"Added 'Dentist Appointment' for next Tuesday at 3:00 PM\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"check availability for this weekend\"\n",
    "            {{\"response\": \"This weekend is free\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            # Checking schedule\n",
    "            action: \"what's on my calendar today?\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"tv_display\", \"request\": \"Display today's schedule: Online meeting at 9:00 AM, Have lunch with Sarah at 'Mama's Burger' at 1 PM, Project review at 3 PM in your office\"}}}}\n",
    "\n",
    "            action: \"check the location of my next appointment\"\n",
    "            Note: calendar doesn't know what time it is, so it can't directly provide information about the next event\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"clock\", \"request\": \"What time is it now? That way I can confirm what the next schedule is\"}}}}\n",
    "\n",
    "            action: \"do I have any meetings tomorrow?\"\n",
    "            Note：There's no need to ask what time it is now\n",
    "            {{\"response\": \"Yes, you have 2 meetings tomorrow: 9 AM Team Meeting and 2 PM Client Call\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"check if I am free this Friday night\"\n",
    "            {{\"response\": \"You are free this Friday night\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"show my schedule on the screen\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"tv_display\", \"request\": \"Display today's calendar: 9am Team Standup, 1pm Lunch, 3pm Review\"}}}}\n",
    "\n",
    "            action: \"What time does my next meeting start?\"\n",
    "            Note: calendar doesn't know what time it is, so it can't directly provide information about the next event\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"clock\", \"request\": \"what time is it now?\"}}}}\n",
    "\n",
    "            action: \"display schedule\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"tv_display\", \"request\": \"Display today's calendar: 9am Team Standup, 1pm Lunch, 3pm Review\"}}}}\n",
    "\n",
    "            action: \"show my schedule\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"tv_display\", \"request\": \"Display today's calendar: 9am Team Standup, 1pm Lunch, 3pm Review\"}}}}\n",
    "\n",
    "            # Need external information\n",
    "            action: \"find a good time to eat dinner next week and add it to my calendar\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"What are the operating hours of the restaurants near me for dinner?\"}}}}\n",
    "\n",
    "            # Canceling\n",
    "            action: \"cancel tomorrow's dentist appointment\"\n",
    "            {{\"response\": \"Cancelled the dentist appointment for tomorrow\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            CRITICAL: Output ONLY pure JSON.\n",
    "\n",
    "            Output format: {{\"response\": \"your result\" or \"\", \"collaboration_request\": {{\"target\": \"agent_name\", \"request\": \"what you need\"}} or {{}}}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"action\",\"task_history\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"action\": action,\n",
    "            \"task_history\": task_history,\n",
    "        })\n",
    "\n",
    "        if result.get(\"collaboration_request\") and result[\"collaboration_request\"].get(\"target\"):\n",
    "            collaboration = result[\"collaboration_request\"]\n",
    "            new_entry = {\n",
    "                \"device\": \"calendar\",\n",
    "                \"type\": \"collaboration_request\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\":{\n",
    "                    \"target\": collaboration[\"target\"],\n",
    "                    \"request\": collaboration[\"request\"],\n",
    "                }\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"collaboration_request\": {\n",
    "                        \"requester\": \"calendar\",\n",
    "                        \"target\": collaboration[\"target\"],\n",
    "                        \"request\": collaboration[\"request\"],\n",
    "                    },\n",
    "                    \"pending_task\": {\n",
    "                        \"device\": \"calendar\",\n",
    "                        \"action\": action,\n",
    "                        \"waiting_for\": collaboration[\"target\"]\n",
    "                    },\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=f\"{collaboration['target']}_agent\"\n",
    "            )\n",
    "        else:\n",
    "            remaining_tasks = task_queue[1:]\n",
    "            calendar_result = result.get(\"response\")\n",
    "            new_entry = {\n",
    "                \"device\": \"calendar\",\n",
    "                \"type\": \"task_completion\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": calendar_result,\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"calendar_result\": calendar_result,\n",
    "                    \"task_queue\": remaining_tasks,\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=\"task_planner\"\n",
    "            )\n"
   ],
   "id": "5967c693978435fc",
   "outputs": [],
   "execution_count": 83
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Display info**",
   "id": "a123f35def1f1ffe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.269380Z",
     "start_time": "2026-01-05T04:14:46.264042Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tv_display_agent(state: SmartHomeState) -> Command:\n",
    "    task_queue = state.get(\"task_queue\", [])\n",
    "    collaboration_request = state.get(\"collaboration_request\")\n",
    "    pending_task = state.get(\"pending_task\")\n",
    "    task_history = state.get(\"task_history\",[])\n",
    "\n",
    "    if collaboration_request and collaboration_request.get(\"target\") == \"tv_display\":\n",
    "        requester = collaboration_request.get(\"requester\")\n",
    "        request = collaboration_request.get(\"request\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Display Agent.\n",
    "\n",
    "            Your capability: Display/Show information in a clear, visual format on the screen\n",
    "\n",
    "            You received a collaboration request from {requester} agent.\n",
    "            Request: {request}\n",
    "\n",
    "            Simulate displaying the requested content.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"confirmation of what you displayed\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"requester\", \"request\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"requester\": requester,\n",
    "            \"request\": request\n",
    "        })\n",
    "        tv_display_response = result.get(\"response\")\n",
    "        new_entry = {\n",
    "            \"device\": \"tv_display\",\n",
    "            \"type\": \"collaboration_response\",\n",
    "            \"action_taken\": request,\n",
    "            \"result\": tv_display_response,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"tv_display_response\": tv_display_response,\n",
    "                \"collaboration_request\": {},\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=f\"{requester}_agent\"\n",
    "        )\n",
    "\n",
    "    # 分支2: 处理协作响应（有pending_task）\n",
    "    elif pending_task and pending_task.get(\"device\") == \"tv_display\":\n",
    "        collaborator = pending_task.get(\"waiting_for\")\n",
    "        response_key = f\"{collaborator}_response\"\n",
    "        collaborator_response = state.get(response_key)\n",
    "        original_action = pending_task.get(\"action\")\n",
    "\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Display Agent completing a task with collaboration information.\n",
    "\n",
    "            Your capability: Display/Show information in a clear, visual format on the screen\n",
    "\n",
    "            Original task: {original_action}\n",
    "            Task history (what happened before this):{task_history}\n",
    "            Collaboration request：{collaboration_request}\n",
    "            Request from {collaborator}: {collaborator_response}\n",
    "\n",
    "            Now display the content using this information. Simulate the display operation.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"confirmation of what was displayed\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"original_action\",\"task_history\",\"collaboration_request\", \"collaborator\", \"collaborator_response\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"original_action\": original_action,\n",
    "            \"task_history\": task_history,\n",
    "            \"collaboration_request\": collaboration_request,\n",
    "            \"collaborator\": collaborator,\n",
    "            \"collaborator_response\": collaborator_response\n",
    "        })\n",
    "\n",
    "        remaining_tasks = task_queue[1:]\n",
    "        tv_display_result = result.get(\"response\")\n",
    "        new_entry = {\n",
    "            \"device\": \"tv_display\",\n",
    "            \"type\": \"task_completion\",\n",
    "            \"action_taken\": original_action,\n",
    "            \"result\": tv_display_result,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"tv_display_result\": tv_display_result ,\n",
    "                \"task_queue\": remaining_tasks,\n",
    "                \"pending_task\": None,\n",
    "                \"collaboration_request\": {},\n",
    "                f\"{collaborator}_response\":None,\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=\"task_planner\"\n",
    "        )\n",
    "\n",
    "    # 分支3: 处理新任务\n",
    "    elif task_queue and task_queue[0].get(\"device\") == \"tv_display\":\n",
    "        action = task_queue[0].get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home TV Display Agent.\n",
    "\n",
    "            Your capability: Display ANY visual content on the TV screen (entertainment, information, schedules, recipes, etc.)\n",
    "\n",
    "            Current task: {action}\n",
    "            Task history: {task_history} which you will know what other device already done\n",
    "\n",
    "            Decision rules:\n",
    "            Step 1: What TYPE of content does the user want to display?\n",
    "\n",
    "            1. Entertainment content (movies, shows, videos, etc.)\n",
    "            2. Information content (schedules, recipes, food inventory, weather, etc.)\n",
    "            3. Simple messages (welcome, notifications, etc.)\n",
    "\n",
    "            Step 2: Can you complete this task independently using your own capabilities ?\n",
    "            First check task history, please note whether there are any other needs.\n",
    "            If YES: Display it directly\n",
    "            If NO: Request collaboration from the appropriate agent\n",
    "\n",
    "            Other agents available for collaboration:\n",
    "            search_engine (look up information, weather, recipes), calendar (schedules, events), clock (time, alarms, set timers), fridge (available food), lighting (light control), thermostat (temperature control), audio_system (playlist info)\n",
    "\n",
    "            Examples:\n",
    "\n",
    "            # Entertainment: need recommendations\n",
    "            action: \"show me a comedy\"\n",
    "            Note: Need recommendations first\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"recommend popular comedy\"}}}}\n",
    "\n",
    "            action: \"show something\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"recommend popular content to watch\"}}}}\n",
    "\n",
    "            action: \"play The Stranger Things for 3 hours\"\n",
    "            Note: Need collaboration from clock agent\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"clock\", \"request\": \"Set a timer for the three-hour watch of The Stranger Things\"}}}}\n",
    "\n",
    "            action: \"find and show a good action movie\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"recommend a good action movie\"}}}}\n",
    "\n",
    "            # Entertainment - exact title\n",
    "            action: \"play Titanic\"\n",
    "            {{\"response\": \"Now playing: Titanic\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            # Schedule/calendar display\n",
    "            action: \"display today's schedule\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"calendar\", \"request\": \"get today's schedule and appointments\"}}}}\n",
    "\n",
    "            # Information/Recipe display\n",
    "            action: \"show cooking instructions on TV\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"get cooking instructions\"}}}}\n",
    "\n",
    "            # Fridge/food inventory display\n",
    "            action: \"display available ingredients\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"fridge\", \"request\": \"get available ingredients\"}}}}\n",
    "\n",
    "            # Time/timer display\n",
    "            action: \"display timer on TV\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"clock\", \"request\": \"get timer status\"}}}}\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"your result\" or \"\", \"collaboration_request\": {{\"target\": \"agent_name\", \"request\": \"what you need\"}} or {{}}}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"action\",\"task_history\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"action\": action,\n",
    "            \"task_history\": task_history,\n",
    "        })\n",
    "\n",
    "        if result.get(\"collaboration_request\") and result[\"collaboration_request\"].get(\"target\"):\n",
    "            collaboration = result[\"collaboration_request\"]\n",
    "\n",
    "            new_entry = {\n",
    "                \"device\": \"tv_display\",\n",
    "                \"type\": \"collaboration_request\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": {\n",
    "                    \"target\": collaboration[\"target\"],\n",
    "                    \"request\": collaboration[\"request\"],\n",
    "                }\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"collaboration_request\": {\n",
    "                        \"requester\": \"tv_display\",\n",
    "                        \"target\": collaboration[\"target\"],\n",
    "                        \"request\": collaboration[\"request\"],\n",
    "                    },\n",
    "                    \"pending_task\": {\n",
    "                        \"device\": \"tv_display\",\n",
    "                        \"action\": action,\n",
    "                        \"waiting_for\": collaboration[\"target\"]\n",
    "                    },\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=f\"{collaboration['target']}_agent\"\n",
    "            )\n",
    "        else:\n",
    "            remaining_tasks = task_queue[1:]\n",
    "            tv_display_result = result.get(\"response\")\n",
    "            new_entry = {\n",
    "                \"device\": \"tv_display\",\n",
    "                \"type\": \"task_completion\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": tv_display_result,\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"tv_display_result\": tv_display_result,\n",
    "                    \"task_queue\": remaining_tasks,\n",
    "                    \"task_history\": task_history + [new_entry]\n",
    "                },\n",
    "                goto=\"task_planner\"\n",
    "            )"
   ],
   "id": "f3b8d85960dc3595",
   "outputs": [],
   "execution_count": 84
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Fridge**",
   "id": "c3a2e6008a411e0d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.278181Z",
     "start_time": "2026-01-05T04:14:46.272691Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def fridge_agent(state: SmartHomeState) -> Command:\n",
    "    task_queue = state.get(\"task_queue\")\n",
    "    collaboration_request = state.get(\"collaboration_request\")\n",
    "    pending_task = state.get(\"pending_task\")\n",
    "    task_history = state.get(\"task_history\",[])\n",
    "\n",
    "    if collaboration_request and collaboration_request.get(\"target\") == \"fridge\":\n",
    "        requester = collaboration_request.get(\"requester\")\n",
    "        request = collaboration_request.get(\"request\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Fridge Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Provide food inventory data (items, quantities, expiry dates)\n",
    "            2. Alert about expiring items\n",
    "            3. Provide available ingredients lists\n",
    "\n",
    "            You received a collaboration request from {requester} agent.\n",
    "            Request need: {request}\n",
    "\n",
    "            Provide fridge information. Simulate reasonable food inventory data.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"your simulated response\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"requester\", \"request\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"requester\": requester,\n",
    "            \"request\": request,\n",
    "        })\n",
    "        fridge_response = result.get(\"response\")\n",
    "        new_entry = {\n",
    "            \"device\": \"fridge\",\n",
    "            \"type\": \"collaboration_response\",\n",
    "            \"action_taken\": request,\n",
    "            \"result\": fridge_response,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"fridge_response\": fridge_response,\n",
    "                \"collaboration_request\": {},\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=f\"{requester}_agent\"\n",
    "        )\n",
    "\n",
    "    elif pending_task and pending_task.get(\"device\") == \"fridge\":\n",
    "        collaborator = pending_task.get(\"waiting_for\")\n",
    "        response_key = f\"{collaborator}_response\"\n",
    "        collaborator_response = state.get(response_key)\n",
    "        original_action = pending_task.get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Fridge Agent completing a task with collaboration information.\n",
    "\n",
    "            1. Provide food inventory data (items, quantities, expiry dates)\n",
    "            2. Alert about expiring items\n",
    "            3. Provide available ingredients lists\n",
    "\n",
    "            Original task: {original_action}\n",
    "            Task history (what happened before this): {task_history}\n",
    "            Collaboration request：{collaboration_request}\n",
    "            Request from {collaborator}: {collaborator_response}\n",
    "\n",
    "            Now complete the fridge task using this information. Simulate reasonable food inventory data.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"task completion message\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"original_action\",\"task_history\",\"collaboration_request\",\"collaborator\", \"collaborator_response\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"original_action\": original_action,\n",
    "            \"collaboration_request\": collaboration_request,\n",
    "            \"task_history\": task_history,\n",
    "            #\"food_inventory\": food_inventory,\n",
    "            \"collaborator\": collaborator,\n",
    "            \"collaborator_response\": collaborator_response\n",
    "        })\n",
    "\n",
    "        fridge_result = result.get(\"response\")\n",
    "        remaining_tasks = task_queue[1:]\n",
    "        new_entry = {\n",
    "            \"device\": \"fridge\",\n",
    "            \"type\": \"task_completion\",\n",
    "            \"action_taken\": original_action,\n",
    "            \"result\": fridge_result,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"fridge_result\": fridge_result,\n",
    "                \"task_queue\": remaining_tasks,\n",
    "                \"pending_task\": None,\n",
    "                \"collaboration_request\": {},\n",
    "                f\"{collaborator}_response\":None,\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=\"task_planner\"\n",
    "        )\n",
    "\n",
    "    elif task_queue and task_queue[0].get(\"device\") == \"fridge\":\n",
    "        action = task_queue[0].get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Fridge Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Provide food inventory data (items, quantities, expiry dates)\n",
    "            2. Alert about expiring items\n",
    "            3. Provide available ingredients lists\n",
    "\n",
    "            Important:\n",
    "            1. NEVER say \"not accessible\" or \"please provide inventory\"\n",
    "            2. NEVER ask the user for information.\n",
    "            3. You DON'T know recipes or what ingredients are needed for specific dishes\n",
    "            4. Simulate reasonable food inventory data.\n",
    "\n",
    "            Current task: {action}\n",
    "            Task history:{task_history} which you will know other device already done\n",
    "\n",
    "            Important: Check task_history first before requesting collaboration.\n",
    "\n",
    "            First, understand what this task requires.\n",
    "            Then, decide based on {task_history}: Can you complete this task independently with your capabilities:\n",
    "            If YES: Provide the result with current inventory data without asking the user questions\n",
    "            If NO: Identify what you need help with and request help from appropriate agent\n",
    "\n",
    "            Other agents available for collaboration:\n",
    "            search_engine (information, recipes), calendar (scheduled events), clock (time, alarms, timers), lighting (light control), thermostat (temperature control), audio_system (music), tv_display(display/show content)\n",
    "\n",
    "            Examples:\n",
    "\n",
    "            action: \"check what food items are available\"\n",
    "            {{\"response\": \"Available: chicken 500g, rice 1kg, vegetables, eggs, milk\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"list ingredients for meal planning\"\n",
    "            {{\"response\": \"Current ingredients: chicken, rice, vegetables, pasta, tomato sauce\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"alert about expiring items\"\n",
    "            {{\"response\": \"Warning: milk expires in 2 days, yogurt expires tomorrow\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            \"user is hungry, suggest quick meal options with available food\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"find quick meal recipes using beef, rice, and vegetables\"}}}}\n",
    "\n",
    "            action: \"suggest recipes using available ingredients\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"find recipes using chicken, rice, and vegetables\"}}}}\n",
    "\n",
    "            action: \"what's in fridge and how to cook\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"find recipes using chicken, rice, and vegetables\"}}}}\n",
    "\n",
    "            action: \"check if I can make spaghetti carbonara with current ingredients\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"What ingredients are needed for spaghetti carbonara?\"}}}}\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"your result\" or \"\", \"collaboration_request\": {{\"target\": \"agent_name\", \"request\": \"what you need\"}} or {{}} }}\n",
    "            \"\"\",\n",
    "            input_variables=[\"action\",\"task_history\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"action\": action,\n",
    "            \"task_history\": task_history,\n",
    "        })\n",
    "\n",
    "        if result.get(\"collaboration_request\") and result[\"collaboration_request\"].get(\"target\"):\n",
    "            collaboration = result[\"collaboration_request\"]\n",
    "            new_entry = {\n",
    "                \"device\": \"fridge\",\n",
    "                \"type\": \"collaboration_request\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": {\n",
    "                    \"target\":collaboration[\"target\"],\n",
    "                    \"request\":collaboration[\"request\"],\n",
    "                }\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"collaboration_request\": {\n",
    "                        \"requester\": \"fridge\",\n",
    "                        \"target\": collaboration[\"target\"],\n",
    "                        \"request\": collaboration[\"request\"]\n",
    "                    },\n",
    "                    \"pending_task\": {\n",
    "                        \"device\": \"fridge\",\n",
    "                        \"action\": action,\n",
    "                        \"waiting_for\": collaboration[\"target\"]\n",
    "                    },\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=f\"{collaboration['target']}_agent\"\n",
    "            )\n",
    "        else:\n",
    "            # Task completed, remove the first task from the current task_queue\n",
    "            remaining_tasks = task_queue[1:]\n",
    "            fridge_result = result.get(\"response\")\n",
    "            new_entry = {\n",
    "                \"device\": \"fridge\",\n",
    "                \"type\": \"task_completion\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": fridge_result,\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"fridge_result\": fridge_result,\n",
    "                    \"task_queue\": remaining_tasks,\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto = \"task_planner\"\n",
    "            )"
   ],
   "id": "5316aabdc29ab45d",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Light**",
   "id": "558748772e5f401"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.286548Z",
     "start_time": "2026-01-05T04:14:46.281222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def lighting_agent(state: SmartHomeState) -> Command:\n",
    "    task_queue = state.get(\"task_queue\", [])\n",
    "    collaboration_request = state.get(\"collaboration_request\")\n",
    "    pending_task = state.get(\"pending_task\")\n",
    "    task_history = state.get(\"task_history\",[])\n",
    "\n",
    "    if collaboration_request and collaboration_request.get(\"target\") == \"lighting\":\n",
    "        requester = collaboration_request.get(\"requester\")\n",
    "        request = collaboration_request.get(\"request\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Lighting Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Turn lights on/off\n",
    "            2. Change light colors\n",
    "            3. Adjust light brightness\n",
    "            4. Set appropriate lighting for different activities (work, sleep, relaxation, eco, etc.)\n",
    "\n",
    "            You received a collaboration request from {requester} agent.\n",
    "            Request: {request}\n",
    "\n",
    "            Simulate the lighting control operation.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"your simulated lighting response\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"requester\", \"request\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"requester\": requester,\n",
    "            \"request\": request\n",
    "        })\n",
    "        lighting_response = result.get(\"response\")\n",
    "        new_entry = {\n",
    "            \"device\": \"lighting\",\n",
    "            \"type\": \"collaboration_response\",\n",
    "            \"action_taken\": request,\n",
    "            \"result\": lighting_response,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"lighting_response\": lighting_response,\n",
    "                \"collaboration_request\": {},\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=f\"{requester}_agent\"\n",
    "        )\n",
    "\n",
    "    elif pending_task and pending_task.get(\"device\") == \"lighting\":\n",
    "        collaborator = pending_task.get(\"waiting_for\")\n",
    "        response_key = f\"{collaborator}_response\"\n",
    "        collaborator_response = state.get(response_key)\n",
    "        original_action = pending_task.get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Lighting Agent completing a task with collaboration information.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Turn lights on/off\n",
    "            2. Change light colors\n",
    "            3. Adjust light brightness\n",
    "            4. Set appropriate lighting for different activities (work, sleep, relaxation, eco, etc.)\n",
    "\n",
    "            Original task: {original_action}\n",
    "            Task history (what happened before this): {task_history}\n",
    "            Collaboration request：{collaboration_request}\n",
    "            Request from {collaborator}: {collaborator_response}\n",
    "\n",
    "            Now complete the lighting task using this information. Simulate reasonable operation.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"task completion message\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"original_action\",\"task_history\",\"collaboration_request\", \"collaborator\", \"collaborator_response\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"original_action\": original_action,\n",
    "            \"task_history\": task_history,\n",
    "            \"collaboration_request\": collaboration_request,\n",
    "            \"collaborator\": collaborator,\n",
    "            \"collaborator_response\": collaborator_response\n",
    "        })\n",
    "        lighting_result = result.get(\"response\")\n",
    "        remaining_tasks = task_queue[1:]\n",
    "        new_entry = {\n",
    "            \"device\": \"lighting\",\n",
    "            \"type\": \"task_completion\",\n",
    "            \"action_taken\": original_action,\n",
    "            \"result\": lighting_result,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"lighting_result\": lighting_result,\n",
    "                \"task_queue\": remaining_tasks,\n",
    "                \"pending_task\": None,\n",
    "                \"collaboration_request\": {},\n",
    "                f\"{collaborator}_response\": None,\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=\"task_planner\"\n",
    "        )\n",
    "\n",
    "    elif task_queue and task_queue[0].get(\"device\") == \"lighting\":\n",
    "        action = task_queue[0].get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Lighting Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Turn lights on/off\n",
    "            2. Change light colors\n",
    "            3. Adjust light brightness\n",
    "            4. Set appropriate lighting for different activities (work, sleep, relaxation, eco, etc.)\n",
    "\n",
    "            Current task: {action}\n",
    "            Task history: {task_history} which you will know what other device already done\n",
    "\n",
    "            IMPORTANT: Always provide complete solutions with specific settings.\n",
    "            DO NOT ask users for additional information, infer reasonable values from context.\n",
    "\n",
    "            First, understand what this task requires.\n",
    "            Then, decide with {task_history}: Can you complete this task independently with your capabilities and task history?\n",
    "\n",
    "            If YES: Simulate the lighting operation and provide the response.\n",
    "            If NO: Identify what you need help with and which agent can provide it.\n",
    "\n",
    "            Other agents available for collaboration:\n",
    "            clock (time, alarms, timers), search_engine (information, weather, recipes), calendar (scheduled events),thermostat (temperature control), audio_system (music), tv_display(display/show content), fridge(food related)\n",
    "\n",
    "            Examples:\n",
    "\n",
    "            action: \"turn on the lights\"\n",
    "            Note: Can do independently with power control\n",
    "            {{\"response\": \"Lights turned on\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"set warm, bright lighting for reading\"\n",
    "            Note: Can do independently with brightness and color control\n",
    "            {{\"response\": \"Set warm white light at 80% brightness for comfortable reading\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"adjust lights based on current time of day\"\n",
    "            Note: Need time information\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"clock\", \"request\": \"what time is it now for appropriate lighting adjustment?\"}}}}\n",
    "\n",
    "            action: \"turn on the light for 2 hour\"\n",
    "            Note: Need collaboration from clock agent\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"clock\", \"request\": \"Set a timer for two hours to turn on the light\"}}}}\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"your result\" or \"\", \"collaboration_request\": {{\"target\": \"agent_name\", \"request\": \"what you need\"}} or {{}}}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"action\",\"task_history\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"action\": action,\n",
    "            \"task_history\": task_history,\n",
    "        })\n",
    "\n",
    "        if result.get(\"collaboration_request\") and result[\"collaboration_request\"].get(\"target\"):\n",
    "            collaboration = result[\"collaboration_request\"]\n",
    "            new_entry = {\n",
    "                \"device\": \"lighting\",\n",
    "                \"type\": \"collaboration_request\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": {\n",
    "                    \"target\": collaboration[\"target\"],\n",
    "                    \"request\": collaboration[\"request\"],\n",
    "                }\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"collaboration_request\": {\n",
    "                        \"requester\": \"lighting\",\n",
    "                        \"target\": collaboration[\"target\"],\n",
    "                        \"request\": collaboration[\"request\"],\n",
    "                    },\n",
    "                    \"pending_task\": {\n",
    "                        \"device\": \"lighting\",\n",
    "                        \"action\": action,\n",
    "                        \"waiting_for\": collaboration[\"target\"]\n",
    "                    },\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=f\"{collaboration['target']}_agent\"\n",
    "            )\n",
    "        else:\n",
    "            remaining_tasks = task_queue[1:]\n",
    "            lighting_result = result.get(\"response\")\n",
    "            new_entry = {\n",
    "                \"device\": \"lighting\",\n",
    "                \"type\": \"task_completion\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": lighting_result,\n",
    "            }\n",
    "\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"lighting_result\": lighting_result,\n",
    "                    \"task_queue\": remaining_tasks,\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=\"task_planner\"\n",
    "            )"
   ],
   "id": "a062935838266ef2",
   "outputs": [],
   "execution_count": 86
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Thermostat**",
   "id": "1a2f85c2c79c67ca"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.295958Z",
     "start_time": "2026-01-05T04:14:46.289910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def thermostat_agent(state: SmartHomeState) -> Command:\n",
    "    task_queue = state.get(\"task_queue\", [])\n",
    "    collaboration_request = state.get(\"collaboration_request\")\n",
    "    pending_task = state.get(\"pending_task\")\n",
    "    task_history = state.get(\"task_history\",[])\n",
    "\n",
    "    if collaboration_request and collaboration_request.get(\"target\") == \"thermostat\":\n",
    "        requester = collaboration_request.get(\"requester\")\n",
    "        request = collaboration_request.get(\"request\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Thermostat Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Temperature control: Adjust heating and cooling\n",
    "            2. Climate optimization: Set comfortable temperature levels\n",
    "            3. Mode settings: Heat, cool, auto, eco modes\n",
    "\n",
    "            You received a collaboration request from {requester} agent.\n",
    "            Request: {request}\n",
    "\n",
    "            Simulate the temperature control operation.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"your simulated thermostat response\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"requester\", \"request\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"requester\": requester,\n",
    "            \"request\": request\n",
    "        })\n",
    "        thermostat_response = result.get(\"response\")\n",
    "        new_entry = {\n",
    "            \"device\": \"thermostat\",\n",
    "            \"type\": \"collaboration_response\",\n",
    "            \"action_taken\": request,\n",
    "            \"result\": thermostat_response,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"thermostat_response\": thermostat_response,\n",
    "                \"collaboration_request\": {},\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=f\"{requester}_agent\"\n",
    "        )\n",
    "\n",
    "    elif pending_task and pending_task.get(\"device\") == \"thermostat\":\n",
    "        collaborator = pending_task.get(\"waiting_for\")\n",
    "        response_key = f\"{collaborator}_response\"\n",
    "        collaborator_response = state.get(response_key)\n",
    "        original_action = pending_task.get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Thermostat Agent completing a task with collaboration information.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Temperature control: Adjust heating and cooling\n",
    "            2. Climate optimization: Set comfortable temperature levels\n",
    "            3. Mode settings: Heat, cool, auto, eco modes\n",
    "\n",
    "            Original task: {original_action}\n",
    "            Task history (what happened before this task):{task_history}\n",
    "            Collaboration request：{collaboration_request}\n",
    "            Request from {collaborator}: {collaborator_response}\n",
    "\n",
    "            Now complete the thermostat task using this information. Simulate the operation.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"task completion message\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"original_action\",\"task_history\",\"collaboration_request\", \"collaborator\", \"collaborator_response\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"original_action\": original_action,\n",
    "            \"task_history\": task_history,\n",
    "            \"collaboration_request\": collaboration_request,\n",
    "            \"collaborator\": collaborator,\n",
    "            \"collaborator_response\": collaborator_response\n",
    "        })\n",
    "\n",
    "        remaining_tasks = task_queue[1:]\n",
    "        thermostat_result = result.get(\"response\")\n",
    "        new_entry = {\n",
    "            \"device\": \"thermostat\",\n",
    "            \"type\": \"task_completion\",\n",
    "            \"action_taken\": original_action,\n",
    "            \"result\": thermostat_result,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"thermostat_result\": thermostat_result,\n",
    "                \"task_queue\": remaining_tasks,\n",
    "                \"pending_task\": None,\n",
    "                \"collaboration_request\": {},\n",
    "                f\"{collaborator}_response\": None,\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=\"task_planner\"\n",
    "        )\n",
    "\n",
    "    elif task_queue and task_queue[0].get(\"device\") == \"thermostat\":\n",
    "        action = task_queue[0].get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Thermostat Agent.\n",
    "\n",
    "            Your capabilities:\n",
    "            1. Temperature control: Adjust heating and cooling\n",
    "            2. Climate optimization: Set comfortable temperature levels\n",
    "            3. Mode settings: Heat, cool, auto, eco modes\n",
    "\n",
    "            Current task: {action}\n",
    "            Task history: {task_history} which you will know what other device already done\n",
    "\n",
    "            IMPORTANT: Always provide complete solutions with specific settings.\n",
    "            DO NOT ask users for additional information, infer reasonable values from context.\n",
    "\n",
    "            First, understand what this task requires.\n",
    "            Then, decide with {task_history}: Can you complete this task independently with your capabilities and current data?\n",
    "\n",
    "            If YES: Simulate the temperature control operation and provide the response.\n",
    "            If NO: Identify what you need help with and which agent can provide it.\n",
    "\n",
    "            Other agents available for collaboration:\n",
    "            clock (time, alarms, timers), search_engine (information, weather, recipes), calendar (scheduled events), audio_system (music), tv_display(display/show content), fridge(food related), lighting(light control)\n",
    "\n",
    "            Examples:\n",
    "\n",
    "            action: \"adjust temperature to 22 degrees\"\n",
    "            Note: Can do independently with temperature control\n",
    "            {{\"response\": \"Temperature set to 22°C\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"create comfortable climate for relaxation\"\n",
    "            Note: Can do independently with climate optimization\n",
    "            {{\"response\": \"Set temperature to 21°C with gentle airflow for relaxation\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"optimize room temperature for energy efficiency\"\n",
    "            Note: Need external energy efficiency knowledge\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"find optimal home temperature settings for energy efficiency\"}}}}\n",
    "\n",
    "            action: \"adjust temperature to 22 degrees for an hour\"\n",
    "            Note: Need external energy efficiency knowledge\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"clock\", \"request\": \"Set a timer for one hour at a temperature of 22 degrees\"}}}}\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"your result\" or \"\", \"collaboration_request\": {{\"target\": \"agent_name\", \"request\": \"what you need\"}} or {{}}}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"action\",\"task_history\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"action\": action,\n",
    "            \"task_history\": task_history,\n",
    "        })\n",
    "\n",
    "        if result.get(\"collaboration_request\") and result[\"collaboration_request\"].get(\"target\"):\n",
    "            collaboration = result[\"collaboration_request\"]\n",
    "            new_entry = {\n",
    "                \"device\": \"thermostat\",\n",
    "                \"type\": \"collaboration_request\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": {\n",
    "                    \"target\": collaboration[\"target\"],\n",
    "                    \"request\": collaboration[\"request\"],\n",
    "                }\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"collaboration_request\": {\n",
    "                        \"requester\": \"thermostat\",\n",
    "                        \"target\": collaboration[\"target\"],\n",
    "                        \"request\": collaboration[\"request\"],\n",
    "                    },\n",
    "                    \"pending_task\": {\n",
    "                        \"device\": \"thermostat\",\n",
    "                        \"action\": action,\n",
    "                        \"waiting_for\": collaboration[\"target\"]\n",
    "                    },\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=f\"{collaboration['target']}_agent\"\n",
    "            )\n",
    "        else:\n",
    "            remaining_tasks = task_queue[1:]\n",
    "            thermostat_result = result.get(\"response\")\n",
    "            new_entry = {\n",
    "                \"device\": \"thermostat\",\n",
    "                \"type\": \"task_completion\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": thermostat_result,\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"thermostat_result\": thermostat_result,\n",
    "                    \"task_queue\": remaining_tasks,\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=\"task_planner\"\n",
    "            )"
   ],
   "id": "e18e1f9f551f43e8",
   "outputs": [],
   "execution_count": 87
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Audio System/Speaker**",
   "id": "ce4a6a5bf02029ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.304975Z",
     "start_time": "2026-01-05T04:14:46.299272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def audio_system_agent(state: SmartHomeState) -> Command:\n",
    "    task_queue = state.get(\"task_queue\", [])\n",
    "    collaboration_request = state.get(\"collaboration_request\")\n",
    "    pending_task = state.get(\"pending_task\")\n",
    "    task_history = state.get(\"task_history\", [])\n",
    "\n",
    "    if collaboration_request and collaboration_request.get(\"target\") == \"audio_system\":\n",
    "        requester = collaboration_request.get(\"requester\")\n",
    "        request = collaboration_request.get(\"request\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Audio System Agent.\n",
    "\n",
    "            Your capability: Play music and audio content, control volume\n",
    "\n",
    "            You received a collaboration request from {requester} agent.\n",
    "            Request: {request}\n",
    "\n",
    "            Simulate the audio system operation.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"your simulated audio system response\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"requester\", \"request\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"requester\": requester,\n",
    "            \"request\": request\n",
    "        })\n",
    "        audio_system_response = result.get(\"response\")\n",
    "        new_entry = {\n",
    "            \"device\": \"audio system\",\n",
    "            \"type\": \"collaboration_response\",\n",
    "            \"action_taken\": request,\n",
    "            \"result\": audio_system_response,\n",
    "        }\n",
    "\n",
    "        return Command(\n",
    "            update={\n",
    "                \"audio_system_response\": audio_system_response,\n",
    "                \"collaboration_request\": {},\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=f\"{requester}_agent\"\n",
    "        )\n",
    "\n",
    "    elif pending_task and pending_task.get(\"device\") == \"audio_system\":\n",
    "        collaborator = pending_task.get(\"waiting_for\")\n",
    "        response_key = f\"{collaborator}_response\"\n",
    "        collaborator_response = state.get(response_key)\n",
    "        original_action = pending_task.get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Audio System Agent completing a task with collaboration information.\n",
    "\n",
    "            Your capability: Play music and audio content, control volume\n",
    "\n",
    "            Original task: {original_action}\n",
    "            Task history (what happened before this task):{task_history}\n",
    "            Collaboration request：{collaboration_request}\n",
    "            Request from {collaborator}: {collaborator_response}\n",
    "\n",
    "            Now complete the audio system task using this information. Simulate the operation.\n",
    "\n",
    "            Don't ask the user for clarification or request help from other agents.\n",
    "            Don't ask the user for choices or preferences.\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"task completion message\"}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"original_action\",\"task_history\",\"collaboration_request\", \"collaborator\", \"collaborator_response\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"original_action\": original_action,\n",
    "            \"task_history\": task_history,\n",
    "            \"collaboration_request\": collaboration_request,\n",
    "            \"collaborator\": collaborator,\n",
    "            \"collaborator_response\": collaborator_response\n",
    "        })\n",
    "        audio_system_result = result.get(\"response\")\n",
    "        remaining_tasks = task_queue[1:]\n",
    "        new_entry = {\n",
    "            \"device\": \"audio system\",\n",
    "            \"type\": \"task_completion\",\n",
    "            \"action_taken\": original_action,\n",
    "            \"result\": audio_system_result,\n",
    "        }\n",
    "        return Command(\n",
    "            update={\n",
    "                \"audio_system_result\": audio_system_result,\n",
    "                \"task_queue\": remaining_tasks,\n",
    "                \"pending_task\": None,\n",
    "                \"collaboration_request\": {},\n",
    "                f\"{collaborator}_response\": None,\n",
    "                \"task_history\": task_history + [new_entry],\n",
    "            },\n",
    "            goto=\"task_planner\"\n",
    "        )\n",
    "\n",
    "    elif task_queue and task_queue[0].get(\"device\") == \"audio_system\":\n",
    "        action = task_queue[0].get(\"action\")\n",
    "\n",
    "        parser = JsonOutputParser()\n",
    "        prompt = PromptTemplate(\n",
    "            template=\"\"\"You are a smart home Audio System Agent.\n",
    "\n",
    "            Your capability: Play music and audio content, control volume\n",
    "\n",
    "            Current task: {action}\n",
    "            Task history: {task_history} which you will know what other device already done\n",
    "\n",
    "            Important:\n",
    "            - You can play specific songs, artists, or albums directly\n",
    "            - You cannot choose music for vague requests - you need recommendations from other agents\n",
    "\n",
    "            How to handle the task:\n",
    "            1. Understand what's needed - focus on what's mentioned, don't overthink\n",
    "            2. Check task_history - has another agent provided relevant information?\n",
    "            3. Can you complete this **independently** with your capability and task_history info?\n",
    "            - If yes: do it and provide response without asking user\n",
    "            - If no: request collaboration from appropriate agent\n",
    "\n",
    "            Other agents available for collaboration:\n",
    "            search_engine (music recommendations, playlists), clock (time, alarms, timers), calendar (event-based audio), lighting (light status), thermostat (temperature control), tv_display(display content), fridge(food related)\n",
    "\n",
    "            Examples:\n",
    "\n",
    "            action: \"play something relaxing at low volume\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"recommend relaxing music\"}}}}\n",
    "\n",
    "            action: \"play classical music, not too loud\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"recommend classical music tracks\"}}}}\n",
    "\n",
    "            # Can do independently with volume control capability\n",
    "            action: \"adjust volume to comfortable level\"\n",
    "            {{\"response\": \"Volume adjusted to 50% for comfortable listening\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            # No type specified - Get general recommendations\n",
    "            action: \"play something\"\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"search_engine\", \"request\": \"recommend popular music to play\"}}}}\n",
    "\n",
    "            # Exact song/artist name\n",
    "            action: \"play Bohemian Rhapsody\"\n",
    "            {{\"response\": \"Now playing: Bohemian Rhapsody by Queen\", \"collaboration_request\": {{}}}}\n",
    "\n",
    "            action: \"play Taylor Swift for 2 hours\"\n",
    "            Note: Note: Cannot independently do - involves timing, beyond just playing music, need collaboration\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"clock\", \"request\": \"set 2 hours timer for playing Taylor Swift's songs\"}}}}\n",
    "\n",
    "            action: \"play Adele for 1 hour\"\n",
    "            Note: Cannot independently do - involves timing, beyond just playing music, need collaboration\n",
    "            {{\"response\": \"\", \"collaboration_request\": {{\"target\": \"clock\", \"request\": \"set 1 hour timer for playing Adele's songs\"}}}}\n",
    "\n",
    "            {format_instructions}\n",
    "\n",
    "            Output only JSON.\n",
    "            Output format: {{\"response\": \"your result\" or \"\", \"collaboration_request\": {{\"target\": \"agent_name\", \"request\": \"what you need\"}} or {{}}}}\n",
    "            \"\"\",\n",
    "            input_variables=[\"action\",\"task_history\"],\n",
    "            partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    "        )\n",
    "\n",
    "        chain = prompt | llm | parser\n",
    "        result = chain.invoke({\n",
    "            \"action\": action,\n",
    "            \"task_history\": task_history,\n",
    "        })\n",
    "\n",
    "        if result.get(\"collaboration_request\") and result[\"collaboration_request\"].get(\"target\"):\n",
    "            collaboration = result[\"collaboration_request\"]\n",
    "            new_entry = {\n",
    "                \"device\": \"audio system\",\n",
    "                \"type\": \"collaboration_request\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": {\n",
    "                    \"target\": collaboration[\"target\"],\n",
    "                    \"request\": collaboration[\"request\"],\n",
    "                }\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"collaboration_request\": {\n",
    "                        \"requester\": \"audio_system\",\n",
    "                        \"target\": collaboration[\"target\"],\n",
    "                        \"request\": collaboration[\"request\"],\n",
    "                    },\n",
    "                    \"pending_task\": {\n",
    "                        \"device\": \"audio_system\",\n",
    "                        \"action\": action,\n",
    "                        \"waiting_for\": collaboration[\"target\"]\n",
    "                    },\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=f\"{collaboration['target']}_agent\"\n",
    "            )\n",
    "        else:\n",
    "            remaining_tasks = task_queue[1:]\n",
    "            audio_system_result = result.get(\"response\")\n",
    "            new_entry = {\n",
    "                \"device\": \"audio system\",\n",
    "                \"type\": \"task_completion\",\n",
    "                \"action_taken\": action,\n",
    "                \"result\": audio_system_result,\n",
    "            }\n",
    "            return Command(\n",
    "                update={\n",
    "                    \"audio_system_result\": audio_system_result,\n",
    "                    \"task_queue\": remaining_tasks,\n",
    "                    \"task_history\": task_history + [new_entry],\n",
    "                },\n",
    "                goto=\"task_planner\"\n",
    "            )"
   ],
   "id": "4fadb51593ca90ea",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Define graph**",
   "id": "cf4c7d07367538e1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-05T04:14:46.325211Z",
     "start_time": "2026-01-05T04:14:46.308342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "builder = StateGraph(SmartHomeState)\n",
    "\n",
    "# add node\n",
    "builder.add_node(\"human\", human)\n",
    "builder.add_node(\"intent_analysis\", intent_analysis)\n",
    "builder.add_node(\"task_planner\", task_planner)\n",
    "builder.add_node(\"clock_agent\", clock_agent)\n",
    "builder.add_node(\"calendar_agent\", calendar_agent)\n",
    "builder.add_node(\"search_engine_agent\", search_engine_agent)\n",
    "builder.add_node(\"tv_display_agent\", tv_display_agent)\n",
    "builder.add_node(\"fridge_agent\", fridge_agent)\n",
    "builder.add_node(\"lighting_agent\", lighting_agent)\n",
    "builder.add_node(\"thermostat_agent\", thermostat_agent)\n",
    "builder.add_node(\"audio_system_agent\", audio_system_agent)\n",
    "\n",
    "# set entry and END\n",
    "builder.add_edge(START, \"human\")\n",
    "builder.add_edge(\"task_planner\", END)\n",
    "\n",
    "graph = builder.compile(checkpointer=MemorySaver())\n"
   ],
   "id": "d7888eb086a3e877",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "import time\n",
    "from smart_home_langgraph import graph\n",
    "from langgraph.types import Command\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"Smart Home Multi-Agent System\")\n",
    "print(\"Type your command (or 'quit' to exit)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "test_count = 0\n",
    "\n",
    "while True:\n",
    "    # get user input\n",
    "    user_input = input(\"\\nYour command: \").strip()\n",
    "\n",
    "    if user_input.lower() in {\"quit\", \"exit\", \"q\"}:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "\n",
    "    if not user_input:\n",
    "        continue\n",
    "\n",
    "    test_count += 1\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"Test {test_count}: {user_input}\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    config = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"task_queue\": [],\n",
    "        \"collaboration_request\": {},\n",
    "        \"task_history\": [],\n",
    "    }\n",
    "\n",
    "    # first run until interrupt\n",
    "    for event in graph.stream(initial_state, config):\n",
    "        pass\n",
    "\n",
    "    for event in graph.stream(Command(resume=user_input), config):\n",
    "        node_name = list(event.keys())[0]\n",
    "        state = event[node_name]\n",
    "\n",
    "        if node_name == \"human\":\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing Node: {node_name}\")\n",
    "        print(f\"State content: {state}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"\\nTime: {execution_time:.2f}s\")"
   ],
   "id": "6aee9d09c1d8f996",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
